{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAN_drN255uI",
        "colab_type": "text"
      },
      "source": [
        "<u><h1 align='center'>Lab2: Building a Sentiment Analysis System</h1></u>\n",
        "\n",
        "    \n",
        "### Problem Definition\n",
        "Given tweets about six US airlines, your task is to predict whether a\n",
        "tweet contains positive, negative, or neutral sentiment about the airline.\n",
        "Twitter data was scraped from February of 2015 and contributors were\n",
        "asked to first classify positive, negative, and neutral tweets, followed\n",
        "by categorizing negative reasons (such as “late flight” or “rude\n",
        "service”).\n",
        "Sentiment analysis is a typical supervised learning task where given a\n",
        "text string, you have to categorize the text string into predefined\n",
        "categories.\n",
        "To solve this problem, you will first import the required libraries and\n",
        "the dataset. Next, you will perform text pre-processing (data cleaning).\n",
        "Then, you have to extract features using Bag of words model, TF-IDF\n",
        "model and word2vec. Finally, you have to use three machine learning\n",
        "algorithms (that you choose) to train and test your sentiment analysis\n",
        "models.\n",
        "\n",
        "\n",
        "### Steps:\n",
        "\n",
        "- import the required libraries and the dataset\n",
        "- text pre-processing\n",
        "- extract features using Bag of words model, TF-IDF model and word2vec\n",
        "- Modeling: choose 3 algorithms\n",
        "\n",
        "# 0. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zywMqd_855uP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "b97f3b8a-da28-4d9a-89ac-adfa3a1be99b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjTXJR9d6H7W",
        "colab_type": "code",
        "outputId": "5a76c19c-0170-41a9-ce7e-aeb730685006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip Tweets.csv.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Tweets.csv.zip\n",
            "  inflating: Tweets.csv              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf8m_RXx55uV",
        "colab_type": "code",
        "outputId": "875bb9ba-8f39-4360-8350-12a657853360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        }
      },
      "source": [
        "data=pd.read_csv('Tweets.csv')\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14640, 15)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...               user_timezone\n",
              "0  570306133677760513  ...  Eastern Time (US & Canada)\n",
              "1  570301130888122368  ...  Pacific Time (US & Canada)\n",
              "2  570301083672813571  ...  Central Time (US & Canada)\n",
              "3  570301031407624196  ...  Pacific Time (US & Canada)\n",
              "4  570300817074462722  ...  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjZBxmoc55uc",
        "colab_type": "code",
        "outputId": "3fe598ae-2feb-467d-8251-ea494afe96f6",
        "colab": {}
      },
      "source": [
        "data.airline_sentiment.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    9178\n",
              "neutral     3099\n",
              "positive    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXpFeiFY55ui",
        "colab_type": "text"
      },
      "source": [
        "# 1. Text Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50hAlh7jcCKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "b4c9bd7b-283c-4159-ed96-ef3c23a64f16"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Z8CSUk55uj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = []\n",
        "for i in range(0,len(data['text'])):\n",
        "    Document = re.sub('[^a-zA-Z]',' ',data['text'][i])\n",
        "    Document = Document.lower()\n",
        "    Document = Document.split()\n",
        "    lem = WordNetLemmatizer()\n",
        "    Document = [lem.lemmatize(word) for word in Document if not word in set(stopwords.words('english'))]\n",
        "    Document = ' '.join(Document)\n",
        "    corpus.append(Document)\n",
        "    \n",
        "Documents = pd.Series(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE9t1CjZ55un",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['cleaned_text']=Documents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1255v3b55ur",
        "colab_type": "text"
      },
      "source": [
        "### Split data into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl_9nspm55ut",
        "colab_type": "code",
        "outputId": "f9a99c6c-8aa6-4e93-9e10-2150b2d4b69c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "Train, Test =train_test_split(data[['cleaned_text','airline_sentiment']],train_size=0.7,random_state=1,stratify=data['airline_sentiment'])\n",
        "#frequency distribution of the class attribute\n",
        "#train set\n",
        "freqTrain = pd.crosstab(index=Train[\"airline_sentiment\"],columns=\"count\")\n",
        "print('frequency distribution of the class attribute in Training set: \\n\\n',freqTrain/freqTrain.sum())\n",
        "#test set\n",
        "freqTest = pd.crosstab(index=Test[\"airline_sentiment\"],columns=\"count\")\n",
        "print('frequency distribution of the class attribute in Test set: \\n\\n',freqTest/freqTest.sum())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "frequency distribution of the class attribute in Training set: \n",
            "\n",
            " col_0                 count\n",
            "airline_sentiment          \n",
            "negative           0.626952\n",
            "neutral            0.211651\n",
            "positive           0.161397\n",
            "frequency distribution of the class attribute in Test set: \n",
            "\n",
            " col_0                 count\n",
            "airline_sentiment          \n",
            "negative           0.626821\n",
            "neutral            0.211749\n",
            "positive           0.161430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tbsujwpl55uy",
        "colab_type": "text"
      },
      "source": [
        "# 3. Feature extraction:\n",
        "   ## a) Bag of Words Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3y9enRp55uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bag of words\n",
        "parseur = CountVectorizer()\n",
        "#create the document term matrix\n",
        "XTrain = parseur.fit_transform(Train['cleaned_text'])\n",
        "mdtTrain = XTrain.toarray()\n",
        "\n",
        "\n",
        "#create the document term matrix for test set\n",
        "mdtTest = parseur.transform(Test['cleaned_text'])\n",
        "mdtTest = mdtTest.toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NMFRVvR55u6",
        "colab_type": "text"
      },
      "source": [
        "   ## b) TF-IDF model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDXf8ASO55u8",
        "colab_type": "code",
        "outputId": "0e71d9fa-884b-4a76-a8bf-a0cb287a5018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "tfidf = TfidfTransformer(norm=\"l2\")\n",
        "tfidf.fit(mdtTrain)\n",
        "print (\"IDF:\",tfidf.idf_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IDF: [4.96707726 9.54178824 9.54178824 ... 8.62549751 9.54178824 9.54178824]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Gz-gUx_D55vB",
        "colab_type": "code",
        "outputId": "a8441c01-5329-420f-fe04-87895b3c5a0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "tf_idf_matrix = tfidf.transform(mdtTrain)\n",
        "print (tf_idf_matrix.todense())\n",
        "tf_idf_matrix = tf_idf_matrix.toarray()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggUN2Ykc55vF",
        "colab_type": "code",
        "outputId": "d8ce2d7f-a151-46b6-a11a-40ae89653d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#create the document term matrix for test set\n",
        "\n",
        "tfidfTest = tfidf.transform(mdtTest)\n",
        "tfidfTest = tfidfTest.toarray()\n",
        "\n",
        "print('size of the matrix: ',tfidfTest.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size of the matrix:  (4392, 10193)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DB9lvMe55vJ",
        "colab_type": "text"
      },
      "source": [
        "   ## c) Word2Vec Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISvfb62h-oSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_preprocessing(Document):\n",
        "    Document = re.sub('[^a-zA-Z]',' ',Document)\n",
        "    Document = Document.lower()\n",
        "    Document = Document.split()\n",
        "    lem = WordNetLemmatizer()\n",
        "    Document = [lem.lemmatize(word) for word in Document if not word in set(stopwords.words('english'))]\n",
        "    return Document"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRhb3yss55vK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def return_sentences(Text):\n",
        "    sentences=[]\n",
        "    for sent in Text.split('.'):\n",
        "        if len(sent)>0:\n",
        "            if '!' in sent:\n",
        "                for sentt in sent.split('!'):\n",
        "                    if len(sentt)>0 :\n",
        "                        if '?' in sentt :\n",
        "                            for senttt in sentt.split('?'):\n",
        "                                if len(senttt)>0:\n",
        "                                    sentences.append(text_preprocessing(senttt))\n",
        "                        else:\n",
        "                            sentences.append(text_preprocessing(sentt))\n",
        "            elif '?' in sent:\n",
        "                for sentt in sent.split('?'):\n",
        "                    if len(sentt)>0 :\n",
        "                        if '!' in sentt :\n",
        "                            for senttt in sentt.split('!'):\n",
        "                                if len(senttt)>0:\n",
        "                                    sentences.append(text_preprocessing(senttt))\n",
        "                        else:\n",
        "                            sentences.append(text_preprocessing(sentt))\n",
        "            else:\n",
        "                sentences.append(text_preprocessing(sent))\n",
        "    return sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nRwrSTf55vP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences=[]\n",
        "for Text in data.text:\n",
        "    sentences.extend(return_sentences(Text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woxleZRo55vV",
        "colab_type": "code",
        "outputId": "2bf02569-2b94-482f-b1ce-3ea1feec6a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "len(sentences)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31396"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46AwiIBz55vb",
        "colab_type": "code",
        "outputId": "f4593a2e-9abf-4dec-a2ea-bcc3382d1970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "sentences[:3]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['virginamerica', 'dhepburn', 'said'],\n",
              " ['virginamerica', 'plus', 'added', 'commercial', 'experience'],\n",
              " ['tacky']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq14u92r55vj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wv_model = Word2Vec(sentences,window=2, size=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaVsf84355vn",
        "colab_type": "code",
        "outputId": "4d635c6d-92a7-4732-c8c9-659d28397df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "wv_model['said']"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.4471718 , -0.29934147, -0.38920575,  0.1000734 , -0.01909727,\n",
              "        0.27499887,  0.19545735, -0.47218323,  0.25697604, -0.0167041 ,\n",
              "        0.01443389,  0.66365325, -0.1103569 ,  0.39532128,  0.03015464,\n",
              "       -0.52213633,  0.08424173,  0.2080123 ,  0.05740016, -0.31629822,\n",
              "       -0.09770916,  0.06987256, -0.02733484, -0.27587214,  0.13436335,\n",
              "        0.21138057,  0.05217331,  0.21302634,  0.18201472,  0.08663177,\n",
              "       -0.14469871,  0.2752368 , -0.37069973,  0.07828341, -0.1065984 ,\n",
              "       -0.25163063,  0.34588635,  0.31370258,  0.11873006,  0.16105972,\n",
              "        0.01733721,  0.04801674, -0.29237103,  0.2580621 , -0.15820517,\n",
              "        0.02220287, -0.21669261, -0.07741657,  0.32924348, -0.07723841,\n",
              "        0.20602418, -0.06632921,  0.08607916, -0.14943449,  0.3197164 ,\n",
              "       -0.11283532, -0.24914756,  0.31342834,  0.1090398 , -0.55513996,\n",
              "       -0.06493661,  0.32072833, -0.38897002, -0.09584168, -0.10547344,\n",
              "        0.03595581,  0.00430905,  0.02573651, -0.11478409, -0.04330037,\n",
              "       -0.258998  ,  0.06082839, -0.16776155, -0.10111891,  0.3204844 ,\n",
              "       -0.1798323 , -0.29640806,  0.17312175,  0.01689295,  0.10098289,\n",
              "       -0.0817216 ,  0.171012  , -0.16191705, -0.2467168 , -0.3121429 ,\n",
              "        0.09762918, -0.5447082 , -0.2644612 , -0.1137128 , -0.2245285 ,\n",
              "       -0.3295298 ,  0.33740968,  0.10295517, -0.27786145,  0.2699755 ,\n",
              "       -0.05114407, -0.25443622,  0.198939  , -0.09066003,  0.28837994],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOeacdemD9tF",
        "colab_type": "code",
        "outputId": "06e731ba-e784-4e0d-a71f-a6e6a78f7d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "wv_model[['said','added']].sum(axis=0)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.6609105 , -0.45178246, -0.5546513 ,  0.13263896, -0.01592185,\n",
              "        0.40004283,  0.25921875, -0.69163656,  0.3526222 , -0.02063236,\n",
              "        0.01933887,  0.95572466, -0.15609789,  0.5798899 ,  0.03072104,\n",
              "       -0.77395433,  0.11112138,  0.31873274,  0.08782855, -0.4581898 ,\n",
              "       -0.14890629,  0.09501515, -0.0539802 , -0.39806914,  0.19964752,\n",
              "        0.28870142,  0.06485673,  0.31498328,  0.27187645,  0.12256157,\n",
              "       -0.21799102,  0.36953637, -0.5321285 ,  0.09695002, -0.14625543,\n",
              "       -0.34877828,  0.52059555,  0.42904764,  0.18915366,  0.21328726,\n",
              "        0.02579263,  0.06916293, -0.42801774,  0.38108358, -0.2170225 ,\n",
              "        0.03533864, -0.31979138, -0.12013727,  0.48967296, -0.11542636,\n",
              "        0.30086482, -0.08685351,  0.10916246, -0.21683541,  0.43818554,\n",
              "       -0.18848783, -0.3685473 ,  0.44920284,  0.16168621, -0.7902601 ,\n",
              "       -0.09649501,  0.45945188, -0.55955964, -0.12683281, -0.16085006,\n",
              "        0.05766296,  0.01756825,  0.04001569, -0.16386864, -0.0664876 ,\n",
              "       -0.3786881 ,  0.07895761, -0.26010206, -0.14384373,  0.43913656,\n",
              "       -0.25641114, -0.41569474,  0.25179967,  0.01866619,  0.14493096,\n",
              "       -0.12166876,  0.26010376, -0.24131301, -0.36565125, -0.45560783,\n",
              "        0.1394947 , -0.7819077 , -0.38492498, -0.1618448 , -0.31957042,\n",
              "       -0.47743672,  0.48527429,  0.15156308, -0.38345772,  0.38830718,\n",
              "       -0.0759794 , -0.34775314,  0.29239765, -0.14117016,  0.44147632],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHzwoafHAzk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vTrain, vTest =train_test_split(data[['text','airline_sentiment']],train_size=0.7,random_state=1,stratify=data['airline_sentiment'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycWYYqXX_6mP",
        "colab_type": "code",
        "outputId": "f8e59e64-9166-4741-9c1e-3100d2c9db05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#TRAIN features\n",
        "trainvect=[]\n",
        "for text in vTrain.text:\n",
        "  text_vect=0\n",
        "  nword=0\n",
        "  sentences_per_doc=return_sentences(text)\n",
        "  for sent in sentences_per_doc:\n",
        "      for word in sent:\n",
        "        if word in wv_model.wv.vocab:\n",
        "          nword+=1\n",
        "          text_vect+=wv_model[word]\n",
        "  trainvect.append(text_vect/nword)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXHfbocpFHAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(trainvect)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-COFnX__6hD",
        "colab_type": "code",
        "outputId": "4b75cbba-dfd2-4319-db16-de24d657d6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#TEST features\n",
        "testvect=[]\n",
        "for text in vTest.text:\n",
        "  text_vect=0\n",
        "  nword=0\n",
        "  sentences_per_doc=return_sentences(text)\n",
        "  for sent in sentences_per_doc:\n",
        "      for word in sent:\n",
        "        if word in wv_model.wv.vocab:\n",
        "          nword+=1\n",
        "          text_vect+=wv_model[word]\n",
        "  testvect.append(text_vect/nword)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hoi3UT54FRMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(testvect)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9D9FPgy55vq",
        "colab_type": "text"
      },
      "source": [
        "# 4. Modeling & prediction & Evaluation:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxeUhIht55vr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifiers = [\n",
        "    \n",
        "    LogisticRegression(solver='liblinear'),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(n_estimators=100),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1EkJtXV55vv",
        "colab_type": "text"
      },
      "source": [
        "## a) BOW model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTr_fEdt55vw",
        "colab_type": "code",
        "outputId": "c2127799-6198-4833-d844-53f2cc03f1ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "results_list = []\n",
        "\n",
        "\n",
        "for clf in classifiers:\n",
        "    clf_name = clf.__class__.__name__\n",
        "    print(\"=\"*30)\n",
        "    print(clf_name)\n",
        "    clf.fit(mdtTrain,Train['airline_sentiment'])\n",
        "\n",
        "        \n",
        "    predTest = clf.predict(mdtTest)\n",
        "    acc = metrics.accuracy_score(Test['airline_sentiment'],predTest)\n",
        "    results_list.append((clf_name, acc*100))\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(results_list,columns=[\"Classifier\", \"Accuracy\"])\n",
        "results_df.set_index('Classifier',inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============================\n",
            "LogisticRegression\n",
            "==============================\n",
            "DecisionTreeClassifier\n",
            "==============================\n",
            "RandomForestClassifier\n",
            "==============================\n",
            "AdaBoostClassifier\n",
            "==============================\n",
            "GaussianNB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEqtexfL55v6",
        "colab_type": "code",
        "outputId": "7cd438a5-a23e-4e93-e6f3-edc82879969a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "results_df.head(6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>78.893443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>68.146630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>75.774135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>71.880692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianNB</th>\n",
              "      <td>48.269581</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Accuracy\n",
              "Classifier                       \n",
              "LogisticRegression      78.893443\n",
              "DecisionTreeClassifier  68.146630\n",
              "RandomForestClassifier  75.774135\n",
              "AdaBoostClassifier      71.880692\n",
              "GaussianNB              48.269581"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CutXg_JA55wD",
        "colab_type": "text"
      },
      "source": [
        "## b) TF-IDF model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSHA6sfO55wE",
        "colab_type": "code",
        "outputId": "df8d19eb-0752-4f25-def8-f7b324f16a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "results_list = []\n",
        "\n",
        "\n",
        "for clf in classifiers:\n",
        "    clf_name = clf.__class__.__name__\n",
        "    print(\"=\"*30)\n",
        "    print(clf_name)\n",
        "    clf.fit(tf_idf_matrix,Train['airline_sentiment'])\n",
        "\n",
        "        \n",
        "    predTest = clf.predict(tfidfTest)\n",
        "    acc = metrics.accuracy_score(Test['airline_sentiment'],predTest)\n",
        "    results_list.append((clf_name, acc*100))\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(results_list,columns=[\"Classifier\", \"Accuracy\"])\n",
        "results_df.set_index('Classifier',inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============================\n",
            "LogisticRegression\n",
            "==============================\n",
            "DecisionTreeClassifier\n",
            "==============================\n",
            "RandomForestClassifier\n",
            "==============================\n",
            "AdaBoostClassifier\n",
            "==============================\n",
            "GaussianNB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a2sUdMf55wJ",
        "colab_type": "code",
        "outputId": "17e8bd87-96dd-4f4e-8934-b0dcdb4a26c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "results_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>77.709472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>66.279599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>75.523679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>71.766849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianNB</th>\n",
              "      <td>48.269581</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Accuracy\n",
              "Classifier                       \n",
              "LogisticRegression      77.709472\n",
              "DecisionTreeClassifier  66.279599\n",
              "RandomForestClassifier  75.523679\n",
              "AdaBoostClassifier      71.766849\n",
              "GaussianNB              48.269581"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M01Ji8R655wM",
        "colab_type": "text"
      },
      "source": [
        "## c) Word2Vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy-4Gtpa55wN",
        "colab_type": "code",
        "outputId": "98acf398-a948-4ed5-e9ad-6c43d815e8dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "results_list = []\n",
        "\n",
        "\n",
        "for clf in classifiers:\n",
        "    clf_name = clf.__class__.__name__\n",
        "    print(\"=\"*30)\n",
        "    print(clf_name)\n",
        "    clf.fit(trainvect,Train['airline_sentiment'])\n",
        "\n",
        "        \n",
        "    predTest = clf.predict(testvect)\n",
        "    acc = metrics.accuracy_score(Test['airline_sentiment'],predTest)\n",
        "    results_list.append((clf_name, acc*100))\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(results_list,columns=[\"Classifier\", \"Accuracy\"])\n",
        "results_df.set_index('Classifier',inplace=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============================\n",
            "LogisticRegression\n",
            "==============================\n",
            "DecisionTreeClassifier\n",
            "==============================\n",
            "RandomForestClassifier\n",
            "==============================\n",
            "AdaBoostClassifier\n",
            "==============================\n",
            "GaussianNB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0jpWc7s55wS",
        "colab_type": "code",
        "outputId": "258b895c-513c-447d-842c-f569b2232bd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "results_df.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Classifier</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>67.440801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>59.995446</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForestClassifier</th>\n",
              "      <td>70.036430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoostClassifier</th>\n",
              "      <td>67.668488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GaussianNB</th>\n",
              "      <td>45.013661</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         Accuracy\n",
              "Classifier                       \n",
              "LogisticRegression      67.440801\n",
              "DecisionTreeClassifier  59.995446\n",
              "RandomForestClassifier  70.036430\n",
              "AdaBoostClassifier      67.668488\n",
              "GaussianNB              45.013661"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}